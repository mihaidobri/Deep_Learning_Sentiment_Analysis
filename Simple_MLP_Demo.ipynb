{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Simple MLP Demo.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mihaidobri/Deep_Learning_Sentiment_Analysis/blob/master/Simple_MLP_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gl6z4pKZbjtD",
        "colab_type": "text"
      },
      "source": [
        "# CNN Demo\n",
        "\n",
        "How to create a CNN with PyTorch to classify a finite number of classes\n",
        "\n",
        "NOTE: If you run into import errors, that means you're probably missing some dependencies. You can create the same conda environment I use by using the file req.txt included and running this terminal command:\n",
        "\n",
        "`conda create -n new_environment_name --file req.txt`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnx0UyzMbjtJ",
        "colab_type": "text"
      },
      "source": [
        "### Prepare the Data\n",
        "The first step to train a neural network is to prepare the data. Here we are going to be using the CIFAR (Canadian Institute for Advanced Research) 10 dataset. The dataset includes 60,000 images of low resolution images each belonging to one of 10 distinct classes.\n",
        "\n",
        "<img src='assets/cifar10_plot.png' style=\"width: 75%; height: 75%\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKs6blaxbjtM",
        "colab_type": "text"
      },
      "source": [
        "### Splitting the data\n",
        "- 50,000 for training\n",
        "- 10,000 for testing\n",
        "\n",
        "<br>\n",
        "This means the neural network will learn from the 50,000 images and then we will test its performance against the 10,000 images it has never seen before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FS--_BXGbjtR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2795e95f-7ecf-4d14-c633-44a48d19b806"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "transform = transforms.Compose([transforms.RandomVerticalFlip(),\n",
        "                                transforms.RandomRotation(20),\n",
        "                                transforms.RandomHorizontalFlip(),\n",
        "                                transforms.ColorJitter(),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5, 0.5, 0.5),\n",
        "                                                     (0.5, 0.5, 0.5))])\n",
        "\n",
        "test_transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                     transforms.Normalize((0.5, 0.5, 0.5),\n",
        "                                                          (0.5, 0.5, 0.5))])\n",
        "\n",
        "train_set = datasets.CIFAR10('~/.pytorch/cifar_data/', download=True, train=True, \\\n",
        "                           transform=transform) \n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=8, shuffle=True)\n",
        "\n",
        "test_set = datasets.CIFAR10('~/.pytorch/cifar_data/', download=True, train=False, \\\n",
        "                          transform=test_transform)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=32, shuffle=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-D0aG6Fbjtd",
        "colab_type": "text"
      },
      "source": [
        "### Define the function we will need\n",
        "\n",
        "- Softmax Function: This function will turn our output layer into probabilities\n",
        "\n",
        "<br>\n",
        "$$ Softmax(x_j)=\\frac{e^{x_j}}{\\sum_{k}^{K}e^{x_k}}$$\n",
        "<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W14WwlBgbjtg",
        "colab_type": "text"
      },
      "source": [
        "### Define our model\n",
        "- Here we define the layers of our model as well as how the inputs should flow through\n",
        "\n",
        "- We will use Pytorch to make this easy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Up2lKMlGbjti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Network(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        \n",
        "        super(Network, self).__init__()\n",
        "        \n",
        "        # Convolutional layers\n",
        "        # This is where the real work will need to be done\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, padding=1)\n",
        "        \n",
        "        # Our pooling function; Try other types of pooling functions!\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        \n",
        "        # MLP Layers\n",
        "        \n",
        "        # Remember, the input to our MLP is \n",
        "        # (number_of_channels * (feaure_map_height * feature_map_width))\n",
        "        self.fc1 = nn.Linear(16 * (16 * 16), 512)\n",
        "        self.fc2 = nn.Linear(512, 512)\n",
        "        self.fc3 = nn.Linear(512, 10)\n",
        "        \n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = torch.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        \n",
        "        # Remember, the input to our MLP is \n",
        "        # (number_of_channels * (feaure_map_height * feature_map_width))\n",
        "        x = x.view(-1, 16 * (16 * 16))\n",
        "        \n",
        "        # Feed forward network\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = self.dropout(F.relu(self.fc2(x)))\n",
        "        x = F.log_softmax(self.fc3(x), dim=1)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdipaHa1bjtp",
        "colab_type": "text"
      },
      "source": [
        "### What is dropout?\n",
        "\n",
        "- This forces the neural network to have all neurons to be important in its decision making\n",
        "\n",
        "- Without it, the network could decide that only a handful of neurons will decide what the output is\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src='assets/dropoutAnimation.gif' style=\"width: 75%; height: 75%\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdrxrH_Sbjts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Here we determine if we have a gpu to use\n",
        "use_cuda = False\n",
        "if torch.cuda.is_available:\n",
        "    use_cuda = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIdSyUYHbjt0",
        "colab_type": "text"
      },
      "source": [
        "## Define the Neural Network and Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8QCMsH5bjt4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "ce91e5f0-fe2a-404a-cb61-ae08f766ca36"
      },
      "source": [
        "# Instantiate our network\n",
        "net = Network()\n",
        "\n",
        "# Determine if we can move our model to a gpu\n",
        "if use_cuda:\n",
        "    print('GPU detected. Moving model to CUDA')\n",
        "    net = net.cuda()\n",
        "\n",
        "# Hyperparameters\n",
        "epochs = 10\n",
        "learning_rate = 0.01 # IMPORTANT: This is way too high; try experimenting\n",
        "\n",
        "# We use this as our loss function because we used log_softmax as our activation function\n",
        "# in the output layer of our network. When we use this loss function combined with\n",
        "# log_softmax it is exactly the same as if we used softmax and cross_entropy\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "# Try experimenting with weight_decay too!\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU detected. Moving model to CUDA\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-9fdf4ac17da8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GPU detected. Moving model to CUDA'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \"\"\"\n\u001b[0;32m--> 311\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    228\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \"\"\"\n\u001b[0;32m--> 311\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    177\u001b[0m             \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[1;32m    178\u001b[0m     \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m     \u001b[0m_cudart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_cudart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0m_cudart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudaGetErrorName\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (38) : no CUDA-capable device is detected at /pytorch/aten/src/THC/THCGeneral.cpp:50"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_izTWQXbjt_",
        "colab_type": "text"
      },
      "source": [
        "### Time to Train!\n",
        "If you change absolutely nothing, you will not get a good model (probably no better than random guesses).\n",
        "Try experimenting with hyperparmeters and model architecture to get above 70%!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "of848AWbbjuB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for e in range(1, epochs+1):\n",
        "    \n",
        "    # Turn dropout on\n",
        "    net.train()\n",
        "    \n",
        "    running_loss = 0\n",
        "    \n",
        "    # Train our model in batches of 64 images, labels\n",
        "    for images, targets in train_loader:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # If we are using a gpu, we need to move the images and labels to it\n",
        "        if use_cuda:\n",
        "            images, targets = images.cuda(), targets.cuda()\n",
        "        \n",
        "        # Forward pass\n",
        "        output = net.forward(images)\n",
        "        \n",
        "        # Calculate loss\n",
        "        loss = criterion(output, targets)\n",
        "        \n",
        "        # Backpropagate\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        \n",
        "    # Turn off dropout in our model\n",
        "    net.eval()\n",
        "    \n",
        "    accuracy = 0\n",
        "    \n",
        "    for images, labels in test_loader:\n",
        "        \n",
        "        if use_cuda:\n",
        "            images, labels = images.cuda(), labels.cuda()\n",
        "            \n",
        "        log_probabilities = net.forward(images)\n",
        "        probabilities = torch.exp(log_probabilities)\n",
        "        _, top_class = probabilities.topk(1, dim=1)\n",
        "        equality = top_class == labels.view(*top_class.shape)\n",
        "        accuracy += torch.mean(equality.type(torch.FloatTensor))\n",
        "        \n",
        "    accuracy = accuracy / len(test_loader)\n",
        "    print('Epoch: {} \\tTraining Loss: {:3f}\\tTesting Accuracy: {:.3f}%'.format(e, running_loss, (accuracy * 100.0)))\n",
        "    print()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hH5u7uD9bjuI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import helper\n",
        "\n",
        "net = net.cpu()\n",
        "net.eval()\n",
        "\n",
        "dataiter = iter(test_loader)\n",
        "images, labels = dataiter.next()\n",
        "img = images[0].unsqueeze(0)\n",
        "\n",
        "# Calculate the class probabilities (softmax) for img\n",
        "ps = torch.exp(net.forward(img))\n",
        "\n",
        "# Plot the image and probabilities\n",
        "helper.view_classify(img[0], ps)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}